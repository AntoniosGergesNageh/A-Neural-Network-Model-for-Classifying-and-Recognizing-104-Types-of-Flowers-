{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntoniosGergesNageh/A-Neural-Network-Model-for-Classifying-and-Recognizing-104-Types-of-Flowers-/blob/main/Pattern_Recognition(_Naive_Bayes_Assignment_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc99f1d",
      "metadata": {
        "id": "0fc99f1d"
      },
      "source": [
        "| Name                   | ID           |\n",
        "|------------------------|--------------|\n",
        "| <font color=\"#008000\" size=\"5\">Antonios Gerges</font> | <font color=\"#008000\" size=\"5\">20221903971</font> |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5e0bf6",
      "metadata": {
        "id": "ef5e0bf6"
      },
      "source": [
        "### Import Necessary Libraries\n",
        "\n",
        "This cell imports essential Python libraries for data handling and machine learning:\n",
        "- **Pandas**: For data manipulation and analysis.\n",
        "- **Sklearn's `train_test_split`**: To split the dataset into training and testing sets.\n",
        "- **Sklearn's `LabelEncoder`**: For encoding labels with a value between 0 and the number of classes minus 1.\n",
        "- **Sklearn's `GaussianNB`**: To apply the Naive Bayes algorithm for classification.\n",
        "- **Sklearn's Metrics**: To evaluate the model using confusion matrix, accuracy, recall, and precision scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f65c96e",
      "metadata": {
        "id": "6f65c96e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88599a2",
      "metadata": {
        "id": "f88599a2"
      },
      "source": [
        "### Steps 0 & 1: Data Loading and Preparation\n",
        "\n",
        "**Step 0: Data Loading**\n",
        "- **Data Source**: Load the dataset from the UCI Machine Learning Repository. This dataset contains demographic and employment details of adults.\n",
        "- **Columns Defined**: Specific names are assigned to each column in the dataset to ensure clarity during manipulation and analysis.\n",
        "\n",
        "**Step 1: Data Preparation**\n",
        "- **Missing Values**: Replace missing values in the dataset with the mode of each column to ensure a consistent dataset without gaps.\n",
        "- **Categorical Encoding**: Convert categorical features into numerical form using `LabelEncoder`, making them suitable for machine learning algorithms.\n",
        "- **Feature Selection**: Separate the dataset into features (`X`) and the target variable (`y`), where the target is the 'income' column.\n",
        "- **Data Splitting**: Divide the data into training and testing sets, allocating 75% for training and 25% for testing. This is crucial for training the model and evaluating its performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46c4df1",
      "metadata": {
        "id": "b46c4df1"
      },
      "outputs": [],
      "source": [
        "# Step 0: Data Loading\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "# Define column names\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv(url, names=columns, na_values=' ?', skipinitialspace=True)\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "# Handle missing values by filling with the mode\n",
        "data = data.fillna(data.mode().iloc[0])\n",
        "\n",
        "# Encode categorical features\n",
        "encoders = {}\n",
        "for col in data.select_dtypes(include=['object']):\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc27858",
      "metadata": {
        "id": "1fc27858"
      },
      "source": [
        "### Steps 2 & 3: Naive Bayes Model Training and Evaluation\n",
        "\n",
        "**Step 2: Naive Bayes Model**\n",
        "- **Model Initialization and Training**: Initialize and train a Gaussian Naive Bayes model using the training data. This model is suitable for classification tasks and works well with features that are normally distributed.\n",
        "\n",
        "**Step 3: Prediction and Evaluation**\n",
        "- **Prediction**: Use the trained model to predict the income classification on the test data.\n",
        "- **Evaluation Metrics**: Calculate key performance metrics to evaluate the model:\n",
        "  - **Accuracy**: Overall correctness of the model.\n",
        "  - **Sensitivity (Recall)**: Ability of the model to correctly identify positive instances.\n",
        "  - **Specificity**: Ability of the model to correctly identify negative instances.\n",
        "  - **Precision**: Accuracy of positive predictions.\n",
        "- **Confusion Matrix**: Display the confusion matrix to visualize true positives, true negatives, false positives, and false negatives.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039a84a3",
      "metadata": {
        "id": "039a84a3",
        "outputId": "de479339-7771-46ba-e3aa-d488eb1f4a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.800761577201818\n",
            "Sensitivity (Recall): 0.6346307925138157\n",
            "Specificity: 0.9501126488574188\n",
            "Precision: 0.7415233415233415\n",
            "Confusion Matrix:\n",
            "[[5904  310]\n",
            " [1312  615]]\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Naive Bayes Model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Prediction and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "sensitivity = recall_score(y_test, y_pred, average='macro')\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Compute specificity\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity (Recall):\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b479bd",
      "metadata": {
        "id": "78b479bd"
      },
      "source": [
        "### Step 4: Posterior Probability Analysis\n",
        "\n",
        "This step focuses on extracting and analyzing the posterior probabilities from the trained Gaussian Naive Bayes model:\n",
        "\n",
        "- **Probability Calculation**: Compute the probability of each test instance belonging to the positive class (income over $50K).\n",
        "- **Specific Instance Probability**: Display the posterior probability for the first test instance, offering insight into how likely it is classified as earning over $50K based on the model's prediction.\n",
        "- **Average Probability**: Optionally, calculate and display the average probability across all test instances, which provides a general sense of how likely the model predicts the positive outcome for the entire test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e770e7e",
      "metadata": {
        "id": "1e770e7e",
        "outputId": "68da5904-30f5-4042-873f-29c9fef6f3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Posterior Probability of making over 50K (first instance): 0.005650398505762114\n",
            "Average Posterior Probability of making over 50K: 0.12565043191240785\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Posterior Probability\n",
        "prob_positive = model.predict_proba(X_test)[:, 1]\n",
        "print(\"Posterior Probability of making over 50K (first instance):\", prob_positive[0])\n",
        "\n",
        "# Optional: Show average probability of making over 50K for all predictions\n",
        "avg_probability = prob_positive.mean()\n",
        "print(\"Average Posterior Probability of making over 50K:\", avg_probability)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b707493",
      "metadata": {
        "id": "5b707493"
      },
      "source": [
        "### Model Evaluation Metrics and Posterior Probabilities\n",
        "\n",
        "| Metric             | Value                              |\n",
        "|--------------------|------------------------------------|\n",
        "| **Accuracy**       | 0.8008                             |\n",
        "| **Sensitivity**    | 0.6346                             |\n",
        "| **Specificity**    | 0.9501                             |\n",
        "| **Precision**      | 0.7415                             |\n",
        "| **Confusion Matrix** | [[5904, 310], [1312, 615]]      |\n",
        "| **Posterior Probability (1st instance)** | 0.0057      |\n",
        "| **Average Posterior Probability**        | 0.1257      |\n",
        "\n",
        "These metrics provide a comprehensive overview of the model's performance, highlighting its accuracy, sensitivity, specificity, precision, and the distribution of outcomes as illustrated by the confusion matrix. The posterior probabilities indicate the likelihood of predicting an income over $50K for both a specific instance and on average.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b0ef1b",
      "metadata": {
        "id": "e6b0ef1b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}